{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embedding using BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': 52, 'countvectorizer': 15, 'provides': 46, 'simple': 48, 'way': 64, 'to': 56, 'both': 6, 'tokenize': 57, 'collection': 12, 'of': 41, 'text': 50, 'documents': 18, 'and': 2, 'build': 7, 'vocabulary': 63, 'known': 33, 'words': 69, 'but': 8, 'also': 0, 'encode': 20, 'new': 39, 'using': 60, 'that': 51, 'you': 70, 'can': 10, 'use': 59, 'it': 32, 'as': 4, 'follows': 24, 'create': 16, 'an': 1, 'instance': 29, 'class': 11, 'call': 9, 'fit': 23, 'function': 27, 'in': 28, 'order': 45, 'learn': 34, 'from': 26, 'one': 43, 'or': 44, 'more': 37, 'transform': 58, 'on': 42, 'needed': 38, 'each': 19, 'vector': 61, 'encoded': 21, 'is': 31, 'returned': 47, 'with': 67, 'length': 35, 'entire': 22, 'integer': 30, 'count': 14, 'for': 25, 'number': 40, 'times': 55, 'word': 68, 'appeared': 3, 'document': 17, 'because': 5, 'these': 54, 'vectors': 62, 'will': 66, 'contain': 13, 'lot': 36, 'zeros': 71, 'we': 65, 'them': 53, 'sparse': 49}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# list of text documents\n",
    "text = [\"\"\"The CountVectorizer provides a simple way to both tokenize a collection of text documents and build a vocabulary of known words, but also to encode new documents using that vocabulary.You can use it as follows:\n",
    "Create an instance of the CountVectorizer class.\n",
    "Call the fit() function in order to learn a vocabulary from one or more documents.\n",
    "Call the transform() function on one or more documents as needed to encode each as a vector.\n",
    "An encoded vector is returned with a length of the entire vocabulary and an integer count for the number of times each word appeared in the document.\n",
    "Because these vectors will contain a lot of zeros, we call them sparse.\"\"\"]\n",
    "# create the transform\n",
    "vectorizer = CountVectorizer()\n",
    "# tokenize and build vocab\n",
    "vectorizer.fit(text)\n",
    "# summarize\n",
    "print(vectorizer.vocabulary_)\n",
    "# encode document\n",
    "vector = vectorizer.transform(text)\n",
    "# summarize encoded vector\n",
    "#Call the transform() function on one or more documents as needed to encode each as a vector.\n",
    "# An encoded vector is returned with a\n",
    "# length of the entire vocabulary and an integer count for the number of times each word appeared in the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 72)\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "[[1 3 2 1 3 1 1 1 1 3 1 1 1 1 1 2 1 1 4 2 2 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1\n",
      "  1 2 1 1 1 6 1 2 2 1 1 1 1 1 1 1 7 1 1 1 4 1 1 1 1 2 1 4 1 1 1 1 1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "print(vector.shape)\n",
    "print(type(vector))\n",
    "print(vector.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0\n",
      "  0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "text2 = [\"the created instance of text documents in class vocabulary puppy\"]\n",
    "vector = vectorizer.transform(text2)\n",
    "print(vector.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word 2 vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
